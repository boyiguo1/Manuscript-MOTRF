@article{hotelling1936relations,
  title={Relations between two sets of variables},
  author={Hotelling, Harold},
  journal={Biometrika},
  volume={28},
  number={3-4},
  pages={321--377},
  year={1936},
  publisher={Oxford University Press}
}

@article{li1991sliced,
  title={Sliced inverse regression for dimension reduction},
  author={Li, Ker-Chau},
  journal={Journal of the American Statistical Association},
  volume={86},
  number={414},
  pages={316--327},
  year={1991},
  publisher={Taylor \& Francis Group}
}

@article{parra2018correlated,
  title={Correlated components analysis-extracting reliable dimensions in multivariate data},
  author={Parra, Lucas C and Haufe, Stefan and Dmochowski, Jacek P},
  journal={arXiv preprint arXiv:1801.08881},
  year={2018}
}

@article{tenenhaus2017regularized,
  title={Regularized generalized canonical correlation analysis: a framework for sequential multiblock component methods},
  author={Tenenhaus, Michel and Tenenhaus, Arthur and Groenen, Patrick JF},
  journal={Psychometrika},
  volume={82},
  number={3},
  pages={737--777},
  year={2017},
  publisher={Springer}
}

@article{rohart2017mixomics,
  title={mixOmics: An R package for ‘omics feature selection and multiple data integration},
  author={Rohart, Florian and Gautier, Beno{\^\i}t and Singh, Amrit and L{\^e} Cao, Kim-Anh},
  journal={PLoS computational biology},
  volume={13},
  number={11},
  pages={e1005752},
  year={2017},
  publisher={Public Library of Science}
}

@article{meng2016dimension,
  title={Dimension reduction techniques for the integrative analysis of multi-omics data},
  author={Meng, Chen and Zeleznik, Oana A and Thallinger, Gerhard G and Kuster, Bernhard and Gholami, Amin M and Culhane, Aed{\'\i}n C},
  journal={Briefings in bioinformatics},
  volume={17},
  number={4},
  pages={628--641},
  year={2016},
  publisher={Oxford University Press}
}

@article{tenenhaus2011regularized,
  title={Regularized generalized canonical correlation analysis},
  author={Tenenhaus, Arthur and Tenenhaus, Michel},
  journal={Psychometrika},
  volume={76},
  number={2},
  pages={257},
  year={2011},
  publisher={Springer}
}

@book{kaplan2008structural,
  title={Structural equation modeling: Foundations and extensions},
  author={Kaplan, David},
  volume={10},
  year={2008},
  publisher={Sage Publications}
}

@article{wold2001pls,
  title={PLS-regression: a basic tool of chemometrics},
  author={Wold, Svante and Sj{\"o}str{\"o}m, Michael and Eriksson, Lennart},
  journal={Chemometrics and intelligent laboratory systems},
  volume={58},
  number={2},
  pages={109--130},
  year={2001},
  publisher={Elsevier}
}

@article{geurts2006extremely,
  title={Extremely randomized trees},
  author={Geurts, Pierre and Ernst, Damien and Wehenkel, Louis},
  journal={Machine learning},
  volume={63},
  number={1},
  pages={3--42},
  year={2006},
  publisher={Springer}
}

@book{cook2009regression,
  title={Regression graphics: Ideas for studying regressions through graphics},
  author={Cook, R Dennis},
  volume={482},
  year={2009},
  publisher={John Wiley \& Sons}
}

@article{cook2010envelope,
  title={Envelope models for parsimonious and efficient multivariate linear regression},
  author={Cook, R Dennis and Li, Bing and Chiaromonte, Francesca},
  journal={Statistica Sinica},
  pages={927--960},
  year={2010},
  publisher={JSTOR}
}

@article{rubin1974estimating,
  title={Estimating causal effects of treatments in randomized and nonrandomized studies.},
  author={Rubin, Donald B},
  journal={Journal of educational Psychology},
  volume={66},
  number={5},
  pages={688},
  year={1974},
  publisher={American Psychological Association}
}

@article{hardoon2004canonical,
  title={Canonical correlation analysis: An overview with application to learning methods},
  author={Hardoon, David R and Szedmak, Sandor and Shawe-Taylor, John},
  journal={Neural computation},
  volume={16},
  number={12},
  pages={2639--2664},
  year={2004},
  publisher={MIT Press}
}

@article{egozcue2003isometric,
  title={Isometric logratio transformations for compositional data analysis},
  author={Egozcue, Juan Jos{\'e} and Pawlowsky-Glahn, Vera and Mateu-Figueras, Gl{\`o}ria and Barcelo-Vidal, Carles},
  journal={Mathematical Geology},
  volume={35},
  number={3},
  pages={279--300},
  year={2003},
  publisher={Springer}
}

@article{li2019statistical,
  title={Statistical and Computational Methods in Microbiome and Metagenomics},
  author={Li, Hongzhe},
  journal={Handbook of Statistical Genomics: Two Volume Set},
  pages={977--550},
  year={2019},
  publisher={Wiley Online Library}
}

@article{zhu2016individualizing,
  title={Individualizing drug dosage with longitudinal data},
  author={Zhu, Xiaolu and Qu, Annie},
  journal={Statistics in medicine},
  volume={35},
  number={24},
  pages={4474--4488},
  year={2016},
  publisher={Wiley Online Library}
}

@inproceedings{menze2011oblique,
  title={On oblique random forests},
  author={Menze, Bjoern H and Kelm, B Michael and Splitthoff, Daniel N and Koethe, Ullrich and Hamprecht, Fred A},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={453--469},
  year={2011},
  organization={Springer}
}

@article{Collins2015,
abstract = {President Obama has announced a research initiative that aims to accelerate progress toward a new era of precision medicine, with a near-term focus on cancers and a longer-term aim to generate knowledge applicable to the whole range of health and disease.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Collins, Francis S. and Varmus, Harold},
doi = {10.1056/NEJMp1500523},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/BOYI/Downloads/nejmp1500523.pdf:pdf},
isbn = {0028-4793},
issn = {0028-4793},
journal = {New England Journal of Medicine},
month = {feb},
number = {9},
pages = {793--795},
pmid = {20573919},
title = {{A New Initiative on Precision Medicine}},
volume = {372},
year = {2015}
}

@article{Caulfield2017,
  title={The 100,000 genomes project protocol},
  author={Caulfield, M and Davies, J and Dennys, M and Elbahy, L and Fowler, T and Hill, S and Woods, KL},
  journal={figshare.},
  year={2017}
}

@article {Peplowi1757,
	author = {Peplow, Mark},
	title = {The 100 000 Genomes Project},
	volume = {353},
	year = {2016},
	doi = {10.1136/bmj.i1757},
	publisher = {BMJ Publishing Group Ltd},
	journal = {BMJ}
}

@article{ball2014harvard,
	title={Harvard Personal Genome Project: lessons from participatory public research},
	author={Ball, Madeleine P and Bobe, Jason R and Chou, Michael F and Clegg, Tom and Estep, Preston W and Lunshof, Jeantine E and Vandewege, Ward and Zaranek, Alexander Wait and Church, George M},
	journal={Genome medicine},
	volume={6},
	number={2},
	pages={10},
	year={2014},
	publisher={BioMed Central}
}

@article{Allofus2018,
  title={The “All of Us” research program},
  author={All of Us Research Program Investigators},
  journal={New England Journal of Medicine},
  volume={381},
  number={7},
  pages={668--676},
  year={2019},
  publisher={Mass Medical Soc}
}

@article{Brinkley2010,
	abstract = {For many diseases where there are several treatment options often there is no consensus on the best treatment to give individual patients. In such cases, it may be necessary to define a strategy for treatment assignment; that is, an algorithm that dictates the treatment an individual should receive based on their measured characteristics. Such a strategy or algorithm is also referred to as a treatment regime. The optimal treatment regime is the strategy that would provide the most public health benefit by minimizing as many poor outcomes as possible. Using a measure that is a generalization of attributable risk (AR) and notions of potential outcomes, we derive an estimator for the proportion of events that could have been prevented had the optimal treatment regime been implemented. Traditional AR studies look at the added risk that can be attributed to exposure of some contaminant; here we will instead study the benefit that can be attributed to using the optimal treatment strategy. We will show how regression models can be used to estimate the optimal treatment strategy and the attributable benefit of that strategy. We also derive the large sample properties of this estimator. As a motivating example, we will apply our methods to an observational study of 3856 patients treated at the Duke University Medical Center with prior coronary artery bypass graft surgery and further heart-related problems requiring a catheterization. The patients may be treated with either medical therapy alone or a combination of medical therapy and percutaneous coronary intervention without a general consensus on which is the best treatment for individual patients.},
	author = {Brinkley, Jason and Tsiatis, Anastasios and Anstrom, Kevin J.},
	doi = {10.1111/j.1541-0420.2009.01282.x},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Manuscript, Regime - 2010 - NIH Public Access.pdf:pdf},
	issn = {0006341X},
	journal = {Biometrics},
	keywords = {Attributable risk (AR),Causal inference,Influence function,Optimal treatment regime},
	number = {2},
	pages = {512--522},
	pmid = {19508237},
	title = {{A generalized estimator of the attributable benefit of an optimal treatment regime}},
	volume = {66},
	year = {2010}
}

@article{qian2011performance,
	title={Performance guarantees for individualized treatment rules},
	author={Qian, Min and Murphy, Susan A},
	journal={Annals of statistics},
	volume={39},
	number={2},
	pages={1180},
	year={2011},
	publisher={NIH Public Access}
}

@article{Cai2011,
	abstract = {Suppose that under the conventional randomized clinical trial setting, a new therapy is compared with a standard treatment. In this article, we propose a systematic, 2-stage estimation procedure for the subject-level treatment differences for future patient's disease management and treatment selections. To construct this procedure, we first utilize a parametric or semiparametric method to estimate individual-level treatment differences, and use these estimates to create an index scoring system for grouping patients. We then consistently estimate the average treatment difference for each subgroup of subjects via a nonparametric function estimation method. Furthermore, pointwise and simultaneous interval estimates are constructed to make inferences about such subgroup-specific treatment differences. The new proposal is illustrated with the data from a clinical trial for evaluating the efficacy and toxicity of a 3-drug combination versus a standard 2-drug combination for treating HIV-1-infected patients.},
	author = {Cai, Tianxi and Tian, Lu and Wong, Peggy H and Wei, L J},
	doi = {10.1093/biostatistics/kxq060},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Cai et al. - 2011 - Analysis of randomized comparative clinical trial data for personalized treatment selections.pdf:pdf},
	isbn = {1468-4357 (Electronic)$\backslash$r1465-4644 (Linking)},
	issn = {1468-4357},
	journal = {Biostatistics (Oxford, England)},
	keywords = {Age Factors,Algorithms,Anti-Retroviral Agents,Anti-Retroviral Agents: administration {\&} dosage,Anti-Retroviral Agents: adverse effects,Anti-Retroviral Agents: therapeutic use,CD4 Lymphocyte Count,Combination,Combination: adverse effects,Computer Simulation,Drug Therapy,HIV Infections,HIV Infections: drug therapy,HIV-1,Humans,Models,Precision Medicine,Precision Medicine: methods,RNA,Randomized Controlled Trials as Topic,Randomized Controlled Trials as Topic: statistics,Reproducibility of Results,Statistical,Treatment Outcome,Viral,Viral: blood},
	number = {2},
	pages = {270--82},
	pmid = {20876663},
	title = {{Analysis of randomized comparative clinical trial data for personalized treatment selections.}},
	volume = {12},
	year = {2011}
}



@article{athey2019generalized,
  title={Generalized random forests},
  author={Athey, Susan and Tibshirani, Julie and Wager, Stefan},
  journal={The Annals of Statistics},
  volume={47},
  number={2},
  pages={1148--1178},
  year={2019},
  publisher={Institute of Mathematical Statistics}
}
}

@article{leblanc1992relative,
  title={Relative risk trees for censored survival data},
  author={LeBlanc, Michael and Crowley, John},
  journal={Biometrics},
  pages={411--425},
  year={1992},
  publisher={JSTOR}
}

@article{gordon1985tree,
  title={Tree-structured survival analysis.},
  author={Gordon, Louis and Olshen, Richard A},
  journal={Cancer treatment reports},
  volume={69},
  number={10},
  pages={1065--1069},
  year={1985}
}

@article{athey2016recursive,
  title={Recursive partitioning for heterogeneous causal effects},
  author={Athey, Susan and Imbens, Guido},
  journal={Proceedings of the National Academy of Sciences},
  volume={113},
  number={27},
  pages={7353--7360},
  year={2016},
  publisher={National Acad Sciences}
}

@article{meinshausen2006quantile,
  title={Quantile regression forests},
  author={Meinshausen, Nicolai},
  journal={Journal of Machine Learning Research},
  volume={7},
  number={Jun},
  pages={983--999},
  year={2006}
}

@article{zhu2012recursively,
  title={Recursively imputed survival trees},
  author={Zhu, Ruoqing and Kosorok, Michael R},
  journal={Journal of the American Statistical Association},
  volume={107},
  number={497},
  pages={331--340},
  year={2012},
  publisher={Taylor \& Francis Group}
}

@article{hothorn2005survival,
  title={Survival ensembles},
  author={Hothorn, Torsten and B{\"u}hlmann, Peter and Dudoit, Sandrine and Molinaro, Annette and Van Der Laan, Mark J},
  journal={Biostatistics},
  volume={7},
  number={3},
  pages={355--373},
  year={2005},
  publisher={Oxford University Press}
}

@article{ishwaran2008random,
  title={Random survival forests},
  author={Ishwaran, Hemant and Kogalur, Udaya B and Blackstone, Eugene H and Lauer, Michael S},
  journal={The annals of applied statistics},
  pages={841--860},
  year={2008},
  publisher={JSTOR}
}

@book{kosorok2015adaptive,
  title={Adaptive Treatment Strategies in Practice: Planning Trials and Analyzing Data for Personalized Medicine},
  author={Kosorok, Michael R and Moodie, Erica EM},
  volume={21},
  year={2015},
  publisher={SIAM}
}

@article{breiman1996bagging,
  title={Bagging predictors},
  author={Breiman, Leo},
  journal={Machine learning},
  volume={24},
  number={2},
  pages={123--140},
  year={1996},
  publisher={Springer}
}

@article{breiman2001random,
  title={Random forests},
  author={Breiman, Leo},
  journal={Machine learning},
  volume={45},
  number={1},
  pages={5--32},
  year={2001},
  publisher={Springer}
}

@article{zhang2012robust,
	title={A robust method for estimating optimal treatment regimes},
	author={Zhang, Baqun and Tsiatis, Anastasios A and Laber, Eric B and Davidian, Marie},
	journal={Biometrics},
	volume={68},
	number={4},
	pages={1010--1018},
	year={2012},
	publisher={Wiley Online Library}
}

@article {Loh2015,
	author = {Loh, Wei-Yin and He, Xu and Man, Michael},
	title = {A regression tree approach to identifying subgroups with differential treatment effects},
	journal = {Statistics in Medicine},
	volume = {34},
	number = {11},
	issn = {1097-0258},
	doi = {10.1002/sim.6454},
	pages = {1818--1833},
	keywords = {missing values, proportional hazards, selection bias, bootstrap},
	year = {2015},
	note = {sim.6454},
	abstract = {In the fight against hard-to-treat diseases such as cancer, it is often difficult to discover new treatments that benefit all subjects. For regulatory agency approval, it is more practical to identify subgroups of subjects for whom the treatment has an enhanced effect. Regression trees are natural for this task because they partition the data space. We briefly review existing regression tree algorithms. Then, we introduce three new ones that are practically free of selection bias and are applicable to data from randomized trials with two or more treatments, censored response variables, and missing values in the predictor variables. The algorithms extend the generalized unbiased interaction detection and estimation (GUIDE) approach by using three key ideas: (i) treatment as a linear predictor, (ii) chi-squared tests to detect residual patterns and lack of fit, and (iii) proportional hazards modeling via Poisson regression. Importance scores with thresholds for identifying influential variables are obtained as by-products. A bootstrap technique is used to construct confidence intervals for the treatment effects in each node. The methods are compared using real and simulated data. Copyright © 2015 John Wiley & Sons, Ltd.},
}

@article{Rainforth2015,
    author = {{Rainforth}, T. and {Wood}, F.},
    title = "{Canonical Correlation Forests}",
    journal = {ArXiv e-prints},
    archivePrefix = "arXiv",
    eprint = {1507.05444},
    primaryClass = "stat.ML",
    keywords = {Statistics - Machine Learning, Computer Science - Learning},
    year = 2015,
    month = jul,
    adsurl = {http://adsabs.harvard.edu/abs/2015arXiv150705444R}
}

@article{bjorck1973,
  title={Numerical methods for computing angles between linear subspaces},
  author={Bjorck, Ake and Golub, Gene H},
  journal={Mathematics of computation},
  volume={27},
  number={123},
  pages={579--594},
  year={1973}
}

@article{householder1958,
  title={Unitary triangularization of a nonsymmetric matrix},
  author={Householder, Alston S},
  journal={Journal of the ACM (JACM)},
  volume={5},
  number={4},
  pages={339--342},
  year={1958},
  publisher={ACM}
}

@article{golub1970,
  title={Singular value decomposition and least squares solutions},
  author={Golub, Gene H and Reinsch, Christian},
  journal={Numerische mathematik},
  volume={14},
  number={5},
  pages={403--420},
  year={1970},
  publisher={Springer}
}

@article{holscher2018almond,
  title={Almond Consumption and Processing Affects the Composition of the Gastrointestinal Microbiota of Healthy Adult Men and Women: A Randomized Controlled Trial},
  author={Holscher, Hannah D and Taylor, Andrew M and Swanson, Kelly S and Novotny, Janet A and Baer, David J},
  journal={Nutrients},
  volume={10},
  number={2},
  pages={126},
  year={2018},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@article{HOTELLING1936,
	author = {Hotelling, Harold},
	title = {Relations between two sets of variates},
	journal = {Biometrika},
	volume = {28},
	number = {3-4},
	pages = {321-377},
	year = {1936},
	doi = {10.1093/biomet/28.3-4.321},
	URL = { + http://dx.doi.org/10.1093/biomet/28.3-4.321},
	eprint = {/oup/backfile/content_public/journal/biomet/28/3-4/10.1093/biomet/28.3-4.321/2/28-3-4-321.pdf}
}

@article{Zhu2017,
	abstract = {We propose a subgroup identification approach for inferring optimal and interpretable personalized treatment rules with high-dimensional covariates. Our approach is based on a two-step greedy tree algorithm to pursue signals in a high-dimensional space. In the first step, we transform the treatment selection problem into a weighted classification problem that can utilize tree-based methods. In the second step, we adopt a newly proposed tree-based method, known as reinforcement learning trees, to detect features involved in the optimal treatment rules and to construct binary splitting rules. The method is further extended to right censored survival data by using the accelerated failure time model and introducing double weighting to the classification trees. The performance of the proposed method is demonstrated via simulation studies, as well as analyses of the Cancer Cell Line Encyclopedia (CCLE) data and the Tamoxifen breast cancer data.; {\textcopyright} 2016, The International Biometric Society.},
	author = {Zhu, Ruoqing and Zhao, Ying Qi and Chen, Guanhua and Ma, Shuangge and Zhao, Hongyu},
	doi = {10.1111/biom.12593},
	isbn = {1541-0420 (Electronic)$\backslash$r0006-341X (Linking)},
	issn = {15410420},
	journal = {Biometrics},
	keywords = {High-dimensional data,Optimal treatment rules,Personalized medicine,Reinforcement learning trees,Survival analysis,Tree-based method},
	number = {2},
	pages = {391--400},
	pmid = {27704531},
	title = {{Greedy outcome weighted tree learning of optimal personalized treatment rules}},
	volume = {73},
	year = {2017}
}

@article{Lew2012,
	abstract = {Statistical analysis is universally used in the interpretation of the results of basic biomedical research, being expected by referees and readers alike. Its role in helping researchers to make reliable inference from their work and its contribution to the scientific process cannot be doubted, but can be improved. There is a widespread and pervasive misunderstanding of P-values that limits their utility as a guide to inference, and a change in the manner in which P-values are specified and interpreted will lead to improved outcomes. This paper explains the distinction between Fisher's P-values, which are local indices of evidence against the null hypothesis in the results of a particular experiment, and Neyman-Pearson $\alpha$ levels, which are global rates of false positive errors from unrelated experiments taken as an aggregate. The vast majority of papers published in pharmacological journals specify P-values, either as exact-values or as being less than a value (usually 0.05), but they are interpreted in a hybrid manner that detracts from their Fisherian role as indices of evidence without gaining the control of false positive and false negative error rate offered by a strict Neyman-Pearson approach. An informed choice between those approaches offers substantial advantages to the users of statistical tests over the current accidental hybrid approach.},
	author = {Lew, Michael J},
	doi = {10.1111/j.1476-5381.2012.01931.x},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Lew - 2012 - Bad statistical practice in pharmacology ( and other basic biomedical disciplines ) you probably don ' t know P.pdf:pdf},
	isbn = {1476-5381 (Electronic)$\backslash$r0007-1188 (Linking)},
	issn = {00071188},
	journal = {British Journal of Pharmacology},
	keywords = {P-values,hypothesis tests,scientific inference,significance tests,statistical education,statistical reform,type I errors},
	number = {5},
	pages = {1559--1567},
	pmid = {22394284},
	title = {{Bad statistical practice in pharmacology (and other basic biomedical disciplines): You probably don't know P}},
	volume = {166},
	year = {2012}
}

@article{MacRAE2012,
	archivePrefix = {arXiv},
	arxivId = {NIHMS150003},
	author = {MacRAE},
	doi = {10.1016/j.biotechadv.2011.08.021.Secreted},
	eprint = {NIHMS150003},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/MacRAE - 2012 - next generation GWA time to focus on pheontype.pdf:pdf},
	isbn = {2122633255},
	issn = {15378276},
	journal = {Circulation: Cardiovascular Genetics},
	number = {6},
	pages = {997--1003},
	pmid = {1000000221},
	title = {{next generation GWA: time to focus on pheontype?}},
	volume = {29},
	year = {2012}
}

@article{Goldstein2009,
	abstract = {10.1056/NEJMp0806284},
	annote = {some experts emphasize that small effect sizes don't necessarily mean that a gene variant is of no interest or use
	
	Use our software to calculate a convergence
	
	How would our method apply to rare variants},
	author = {Goldstein, David B},
	doi = {10.1056/NEJMp0806284},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Goldstein - 2009 - Common genetic variation and human traits.pdf:pdf},
	isbn = {1533-4406 (Electronic)$\backslash$n0028-4793 (Linking)},
	issn = {15334406},
	journal = {The New England journal of medicine},
	keywords = {Body Height,Body Height: genetics,Diabetes Mellitus,Disease,Disease: genetics,Drug Design,Genetic Predisposition to Disease,Genetic Predisposition to Disease: genetics,Genetic Variation,Genome-Wide Association Study,Genomics,Humans,Polymorphism,Risk,Single Nucleotide,Type 2,Type 2: genetics},
	number = {17},
	pages = {1696--1698},
	pmid = {19369660},
	title = {{Common genetic variation and human traits.}},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/19369660},
	volume = {360},
	year = {2009}
}

@article{Zollner2007,
	author = {Z{\"{o}}llner, Sebastian and Pritchard, Jonathan K.},
	doi = {10.1086/512821},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Z{\"{o}}llner, Pritchard - 2007 - Overcoming the Winner's Curse Estimating Penetrance Parameters from Case-Control Data.pdf:pdf},
	issn = {00029297},
	journal = {The American Journal of Human Genetics},
	number = {4},
	pages = {605--615},
	title = {{Overcoming the Winner's Curse: Estimating Penetrance Parameters from Case-Control Data}},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0002929707610970},
	volume = {80},
	year = {2007}
}

@article{Zhang2015,
	author = {Zhang, Xinyan and Li, Yan},
	doi = {10.4172/2155-6180.1000281},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Zhang et al. - 2016 - Journal of Biometrics {\&} Biostatistics Statistical Methods in Precision Medicine Employing Systems Biology for Can.pdf:pdf},
	issn = {21556180},
	journal = {Journal of Biometrics {\&} Biostatistics},
	number = {01},
	pages = {1--2},
	title = {{Statistical Methods in Precision Medicine: Employing Systems Biology for Cancer Survival Prediction}},
	url = {https://www.omicsonline.org/open-access/statistical-methods-in-precision-medicine-employing-systems-biology-forcancer-survival-prediction-2155-6180-1000281.php?aid=69005},
	volume = {07},
	year = {2015}
}

@article{Baguley2009,
	abstract = {It is regarded as best practice for psychologists to report effect size when disseminating quantitative research findings. Reporting of effect size in the psychological literature is patchy - though this may be changing - and when reported it is far from clear that appropriate effect size statistics are employed. This paper considers the practice of reporting point estimates of standardized effect size and explores factors such as reliability, range restriction and differences in design that distort standardized effect size unless suitable corrections are employed. For most purposes simple (unstandardized) effect size is more robust and versatile than standardized effect size. Guidelines for deciding what effect size metric to use and how to report it are outlined. Foremost among these are: (i) a preference for simple effect size over standardized effect size, and (ii) the use of confidence intervals to indicate a plausible range of values the effect might take. Deciding on the appropriate effect size statistic to report always requires careful thought and should be influenced by the goals of the researcher, the context of the research and the potential needs of readers.},
	author = {Baguley, Thom},
	doi = {10.1348/000712608X377117},
	file = {:Users/boyiguo/Downloads/Baguley-2009-British{\_}Journal{\_}of{\_}Psychology.pdf:pdf},
	isbn = {0007-1269},
	issn = {00071269},
	journal = {British Journal of Psychology},
	number = {3},
	pages = {603--617},
	pmid = {19017432},
	title = {{Standardized or simple effect size: What should be reported?}},
	url = {http://doi.wiley.com/10.1348/000712608X377117},
	volume = {100},
	year = {2009}
}

@article{Holland2016,
	abstract = {Genome-wide Association Studies (GWAS) result in millions of summary statistics ("z-scores") for single nucleotide polymorphism (SNP) associations with phenotypes. These rich datasets afford deep insights into the nature and extent of genetic contributions to complex phenotypes such as psychiatric disorders, which are understood to have substantial genetic components that arise from very large numbers of SNPs. The complexity of the datasets, however, poses a significant challenge to maximizing their utility. This is reflected in a need for better understanding the landscape of z-scores, as such knowledge would enhance causal SNP and gene discovery, help elucidate mechanistic pathways, and inform future study design. Here we present a parsimonious methodology for modeling effect sizes and replication probabilities, relying only on summary statistics from GWAS substudies, and a scheme allowing for direct empirical validation. We show that modeling z-scores as a mixture of Gaussians is conceptually appropriate, in particular taking into account ubiquitous non-null effects that are likely in the datasets due to weak linkage disequilibrium with causal SNPs. The four-parameter model allows for estimating the degree of polygenicity of the phenotype and predicting the proportion of chip heritability explainable by genome-wide significant SNPs in future studies with larger sample sizes. We apply the model to recent GWAS of schizophrenia (N = 82,315) and putamen volume (N = 12,596), with approximately 9.3 million SNP z-scores in both cases. We show that, over a broad range of z-scores and sample sizes, the model accurately predicts expectation estimates of true effect sizes and replication probabilities in multistage GWAS designs. We assess the degree to which effect sizes are over-estimated when based on linear-regression association coefficients. We estimate the polygenicity of schizophrenia to be 0.037 and the putamen to be 0.001, while the respective sample sizes required to approach fully explaining the chip heritability are 10(6) and 10(5). The model can be extended to incorporate prior knowledge such as pleiotropy and SNP annotation. The current findings suggest that the model is applicable to a broad array of complex phenotypes and will enhance understanding of their genetic architectures.},
	author = {Holland, Dominic and Wang, Yunpeng and Thompson, Wesley K and Schork, Andrew and Chen, Chi-Hua and Lo, Min-Tzu and Witoelar, Aree and Werge, Thomas and O'Donovan, Michael and Andreassen, Ole A and Dale, Anders M},
	doi = {10.3389/fgene.2016.00015},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Holland et al. - 2016 - Estimating Effect Sizes and Expected Replication Probabilities from GWAS Summary Statistics.pdf:pdf},
	issn = {1664-8021},
	journal = {Frontiers in genetics},
	keywords = {GWAS,Gaussian mixture model,Heritability.,Putamen,SNP discovery,Schizophrenia,effect size},
	number = {February},
	pages = {15},
	pmid = {26909100},
	title = {{Estimating Effect Sizes and Expected Replication Probabilities from GWAS Summary Statistics.}},
	url = {http://journal.frontiersin.org/article/10.3389/fgene.2016.00015/abstract},
	volume = {7},
	year = {2016}
}



@article{Jameson2015,
	abstract = {Title VIII of the American Recovery and Rein- vestment Act of 2009 authorizes the expenditure of {\$}1.1 billion to conduct research comparing “clinical outcomes, effectiveness, and appropri- ateness of items, services, and procedures that are used to prevent, diagnose, or treat diseases, dis- orders, and other health conditions.” Federal support of “comparative effectiveness” research has been viewed as a cornerstone in controlling runaway health care costs. Although cost is not mentioned explicitly in the comparative effectiveness legislation, the American College of Physicians and others have called for cost-effectiveness analysis — assess- ment of the added improvement in health out- comes relative to cost — to be on the agenda for comparative effectiveness research.1,2 This ap- proach has come under harsh criticism from some who view it as the first step in health care rationing by the government — that cost cutting will mean the withdrawal of expensive treatments with small (but still positive) benefits. Some poli- ticians have therefore tried to restrict any efforts to use comparative effectiveness to guide U.S. health care policy.3},
	author = {Jameson, J Larry and Longo, Dan L},
	doi = {10.1056/NEJMsb1503104},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Jameson, Longo - 2015 - Precision medicine--personalized, problematic, and promising.pdf:pdf},
	isbn = {1533-4406 (Electronic)$\backslash$r0028-4793 (Linking)},
	issn = {1533-4406},
	journal = {The New England journal of medicine},
	number = {23},
	pages = {2229--34},
	pmid = {26014593},
	title = {{Precision medicine--personalized, problematic, and promising.}},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/26014593},
	volume = {372},
	year = {2015}
}

@article{Klein2007,
	author = {Klein, Robert J},
	doi = {10.1186/1471-2156-8-58},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Klein - 2007 - Power analysis for genome-wide association studies.pdf:pdf},
	issn = {14712156},
	journal = {BMC Genetics},
	number = {1},
	pages = {58},
	title = {{Power analysis for genome-wide association studies}},
	url = {http://www.biomedcentral.com/1471-2156/8/58},
	volume = {8},
	year = {2007}
}

@article{Kraft2008,
	author = {Kraft, Peter and Cox, David G.},
	doi = {10.1016/S0065-2660(07)00417-8},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Kraft, Cox - 2008 - Study Designs for Genome‐Wide Association Studies.pdf:pdf},
	number = {07},
	pages = {465--504},
	title = {{Study Designs for Genome‐Wide Association Studies}},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0065266007004178},
	volume = {60},
	year = {2008}
}


@article{Ma2015,
	abstract = {The process for using statistical inference to establish personalized treatment strategies requires specific techniques for data-analysis that optimize the combination of competing therapies with candidate genetic features and characteristics of the patient and disease. A wide variety of methods have been developed. However, heretofore the usefulness of these recent advances has not been fully recognized by the oncology community, and the scope of their applications has not been summarized. In this paper, we provide an overview of statistical methods for establishing optimal treatment rules for personalized medicine and discuss specific examples in various medical contexts with oncology as an emphasis. We also point the reader to statistical software for implementation of the methods when available.},
	author = {Ma, Junsheng and Hobbs, Brian P. and Stingo, Francesco C.},
	doi = {10.1155/2015/670691},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Ma et al. - 2015 - Statistical Methods for Establishing Personalized Treatment Rules in Oncology.pdf:pdf},
	issn = {23146141},
	journal = {BioMed Research International},
	pages = {1--13},
	publisher = {Hindawi Publishing Corporation},
	title = {{Statistical Methods for Establishing Personalized Treatment Rules in Oncology}},
	url = {http://www.hindawi.com/journals/bmri/2015/670691/},
	volume = {2015},
	year = {2015}
}

@article{Hirschhorn2009,
	abstract = {Human genetiicists seek to understand the inherited basis of human biology and disease, aiming either to gain insights that could eventually improve treatment or to produce useful diagnostic or predictive tests. As recently as 2004, few genetic variants were known to reproducibly influence common polygenic diseases (in- cluding cancer, coronary artery disease, and diabetes) or quanti- tative phenotypes (including lipid levels and blood pressure). This relative ignorance limited poten- tial insights into the pathophysi- ology of common diseases.},
	annote = {The main goal of these studies is not a prediction of individual risk but rather discovery of biologic pathways underlying polygenic disease and traits},
	author = {Hirschhorn, Joel N},
	doi = {10.1056/NEJMp0808934},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Hirschhorn - 2009 - Genomewide association studies--illuminating biologic pathways.pdf:pdf},
	isbn = {1533-4406 (Electronic)$\backslash$r0028-4793 (Linking)},
	issn = {1533-4406},
	journal = {The New England journal of medicine},
	number = {17},
	pages = {1699--1701},
	pmid = {19369661},
	title = {{Genomewide association studies--illuminating biologic pathways.}},
	volume = {360},
	year = {2009}
}

@inproceedings{Kohavi1995,
	abstract = {We review accuracy estimation methods and compare the two most common methods: cross-validation and bootstrap. Recent experimen-tal results on artiicial data and theoretical re-sults in restricted settings have shown that for selecting a good classiier from a set of classi-(model selection), ten-fold cross-validation may be better than the more expensive l e a ve-one-out cross-validation. We report on a large-scale experiment|over half a million runs of C4.5 and a Naive-Bayes algorithm|to estimate the eeects of diierent parameters on these al-gorithms on real-world datasets. For cross-validation, we v ary the number of folds and whether the folds are stratiied or nott for boot-strap, we v ary the number of bootstrap sam-ples. Our results indicate that for real-word datasets similar to ours, the best method to use for model selection is ten-fold stratiied cross validation, even if computation power allows using more folds.},
	archivePrefix = {arXiv},
	arxivId = {arXiv:1011.1669v3},
	author = {Kohavi, Ron},
	booktitle = {Appears in the International Joint Conference on Articial Intelligence (IJCAI)},
	doi = {10.1067/mod.2000.109031},
	eprint = {arXiv:1011.1669v3},
	isbn = {1-55860-363-8},
	issn = {10450823},
	pages = {1--7},
	pmid = {11029742},
	title = {{A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection}},
	url = {http://robotics.stanford.edu/{~}ronnyk},
	year = {1995}
}

@article{Borra2010,
	abstract = {The estimators most widely used to evaluate the prediction error of a non-linear regression model are examined. An extensive simulation approach allowed the comparison of the performance of these estimators for different non-parametric methods, and with varying signal-to-noise ratio and sample size. Estimators based on resampling methods such as Leave-one-out, parametric and non-parametric Bootstrap, as well as repeated Cross Validation methods and Hold-out, were considered. The methods used are Regression Trees, Projection Pursuit Regression and Neural Networks. The repeated-corrected 10-fold Cross-Validation estimator and the Parametric Bootstrap estimator obtained the best performance in the simulations. {\textcopyright} 2010 Elsevier B.V. All rights reserved.},
	author = {Borra, Simone and {Di Ciaccio}, Agostino},
	doi = {10.1016/j.csda.2010.03.004},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Borra, Di Ciaccio - 2010 - Measuring the prediction error. A comparison of cross-validation, bootstrap and covariance penalty methods.pdf:pdf},
	isbn = {0167-9473},
	issn = {01679473},
	journal = {Computational Statistics and Data Analysis},
	keywords = {Bootstrap,Covariance penalty,Cross-validation,Extra-sample error,In-sample error,Leave-one-out,Neural networks,Optimism,Prediction error,Projection pursuit regression,Regression trees},
	number = {12},
	pages = {2976--2989},
	publisher = {Elsevier B.V.},
	title = {{Measuring the prediction error. A comparison of cross-validation, bootstrap and covariance penalty methods}},
	url = {http://dx.doi.org/10.1016/j.csda.2010.03.004},
	volume = {54},
	year = {2010}
}

@article{McCarthy2008,
	abstract = {The past year has witnessed substantial advances in understanding the genetic basis of many common phenotypes of biomedical importance. These advances have been the result of systematic, well-powered, genome-wide surveys exploring the relationships between common sequence variation and disease predisposition. This approach has revealed over 50 disease-susceptibility loci and has provided insights into the allelic architecture of multifactorial traits. At the same time, much has been learned about the successful prosecution of association studies on such a scale. This Review highlights the knowledge gained, defines areas of emerging consensus, and describes the challenges that remain as researchers seek to obtain more complete descriptions of the susceptibility architecture of biomedical traits of interest and to translate the information gathered into improvements in clinical management},
	annote = {Can be used at Introduction or Discussion section.},
	author = {McCarthy, M I and Abecasis, G R and Cardon, L R and Goldstein, D B and LITTLE, J and Ioannidis, J P A and Hirschhorn, J N},
	doi = {10.1038/nrg2344},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/McCarthy et al. - 2008 - Genome-wide association studies for complex traits consensus, uncertainty and challenges.pdf:pdf},
	isbn = {1471-0064 (Electronic)$\backslash$r1471-0056 (Linking)},
	issn = {1471-0056},
	journal = {Nat.Rev.Genet.},
	keywords = {Alleles,Animals,Architecture,Disease,Disease Susceptibility,Genetic,Genetic Diseases,Inborn,Genetic Predisposition to Disease,Genetic Variation,Genome,Human,Human,Humans,Knowledge,Phenotype,Quantitative Trait Loci,Quantitative Trait,Heritable,Susceptibility,Time,Uncertainty,Universities,University,genetics,predisposition,review,study},
	number = {5},
	pages = {356--369},
	pmid = {18398418},
	title = {{Genome-wide association studies for complex traits: consensus, uncertainty and challenges}},
	url = {pm: 18398418},
	volume = {9},
	year = {2008}
}

@article{Ohashi2001,
	abstract = {Genome-wide association studies using a dense map of single nucleotide polymorphism (SNP) markers seem to enable us to detect a number of complex disease genes. In such indirect association studies, whether susceptibility genes can be detected is dependent not only on the degree of linkage disequilibrium between the disease variant and the SNP marker but also on the difference in their allele frequencies. These factors, as well as penetrance of the disease variant, influence the statistical power of such approaches. However, the power of indirect association studies is not well understood. We calculated the number of individuals necessary for the detection of the disease variant in both direct and indirect association studies with a case-control design. The result shows that a remarkable reduction in the statistical power of indirect studies, compared with that of direct ones, is unavoidable in the genome-wide screening of complex disease genes. If there is a large difference in allele frequency between the disease variant and the marker, the disease variant cannot be detected. Because the frequency of the disease variant is unknown, SNP markers with various allele frequencies, or a large number of SNP markers, must be used in indirect association studies. However, if the number of SNP markers is increased, the obtained P value may not reach the significance level due to the Bonferroni adjustment. Thus, to test a possible association between functional variants and a complex disease directly, we should identify such SNPs in as many genes as possible for use in genome-wide association studies.},
	author = {Ohashi, J. and Tokunaga, K.},
	doi = {10.1007/s100380170048},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Ohashi, Tokunaga - 2001 - The power of genome-wide association studies of complex disease genes Statistical limitations of indirect appr.pdf:pdf},
	isbn = {1434-5161 (Print)},
	issn = {14345161},
	journal = {Journal of Human Genetics},
	keywords = {Case-control study,Genome-wide association studies,Market allele frequency,Power linkage disequilibrium,SNPs,Sample size},
	number = {8},
	pages = {478--482},
	pmid = {11501946},
	title = {{The power of genome-wide association studies of complex disease genes: Statistical limitations of indirect approaches using SNP markers}},
	volume = {46},
	year = {2001}
}

@book{Breiman1984,
	abstract = {The methodology used to construct tree structured rules is the focus of this monograph. Unlike many other statistical procedures, which moved from pencil and paper to calculators, this text's use of trees was unthinkable before computers. Both the practical and theoretical sides have been developed in the authors' study of tree methods. Classification and Regression Trees reflects these two sides, covering the use of trees as a data analysis method, and in a more mathematical framework, proving some of their fundamental properties.},
	author = {Breiman, L and Friedman, J H and Olshen, R A and Stone, C J},
	booktitle = {The Wadsworth statisticsprobability series},
	doi = {10.1371/journal.pone.0015807},
	isbn = {0412048418},
	issn = {19326203},
	pages = {368},
	pmid = {462029},
	title = {{Classification and Regression Trees}},
	volume = {19},
	year = {1984}
}

@article{Fritz2012,
	abstract = {The Publication Manual of the American Psychological Association (American Psychological Association, 2001, American Psychological Association, 2010) calls for the reporting of effect sizes and their confidence intervals. Estimates of effect size are useful for determining the practical or theoretical importance of an effect, the relative contributions of factors, and the power of an analysis. We surveyed articles published in 2009 and 2010 in the Journal of Experimental Psychology: General, noting the statistical analyses reported and the associated reporting of effect size estimates. Effect sizes were reported for fewer than half of the analyses; no article reported a confidence interval for an effect size. The most often reported analysis was analysis of variance, and almost half of these reports were not accompanied by effect sizes. Partial $\eta$2 was the most commonly reported effect size estimate for analysis of variance. For t tests, 2/3 of the articles did not report an associated effect size estimate; Cohen's d was the most often reported. We provide a straightforward guide to understanding, selecting, calculating, and interpreting effect sizes for many types of data and to methods for calculating effect size confidence intervals and power analysis.},
	author = {Fritz, Catherine O. and Morris, Peter E. and Richler, Jennifer J.},
	doi = {10.1037/a0024338},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Fritz, Morris, Richler - 2012 - Effect size estimates Current use, calculations, and interpretation.pdf:pdf},
	isbn = {1939-2222; 0022-1015},
	issn = {1939-2222},
	journal = {Journal of Experimental Psychology: General},
	number = {1},
	pages = {2--18},
	pmid = {21823805},
	title = {{Effect size estimates: Current use, calculations, and interpretation.}},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0024338},
	volume = {141},
	year = {2012}
}

@article{Zhao2013,
	abstract = {When comparing a new treatment with a control in a randomized clinical study, the treatment effect is generally assessed by evaluating a summary measure over a specific study population. The success of the trial heavily depends on the choice of such a population. In this paper, we show a systematic, effective way to identify a promising population, for which the new treatment is expected to have a desired benefit, utilizing the data from a current study involving similar comparator treatments. Specifically, using the existing data, we first create a parametric scoring system as a function of multiple multiple baseline covariates to estimate subject-specific treatment differences. Based on this scoring system, we specify a desired level of treatment difference and obtain a subgroup of patients, defined as those whose estimated scores exceed this threshold. An empirically calibrated threshold-specific treatment difference curve across a range of score values is constructed. The subpopulation of patients satisfying any given level of treatment benefit can then be identified accordingly. To avoid bias due to overoptimism, we utilize a cross-training-evaluation method for implementing the above two-step procedure. We then show how to select the best scoring system among all competing models. Furthermore, for cases in which only a single pre-specified working model is involved, inference procedures are proposed for the average treatment difference over a range of score values using the entire data set, and are justified theoretically and numerically. Lastly, the proposals are illustrated with the data from two clinical trials in treating HIV and cardiovascular diseases. Note that if we are not interested in designing a new study for comparing similar treatments, the new procedure can also be quite useful for the management of future patients, so that treatment may be targeted towards those who would receive nontrivial benefits to compensate for the risk or cost of the new treatment.},
	author = {Zhao, Lihui and Tian, Lu and Cai, Tianxi and Claggett, Brian and Wei, L. J.},
	doi = {10.1080/01621459.2013.770705},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Zhao et al. - 2013 - Effectively selecting a target population for a future comparative study.pdf:pdf},
	isbn = {0162-1459 (Print)$\backslash$r0162-1459 (Linking)},
	issn = {01621459},
	journal = {Journal of the American Statistical Association},
	keywords = {Cross-training-evaluation,Lasso procedure,Personalized medicine,Prediction,Ridge regression,Stratified medicine,Subgroup analysis,Variable selection},
	number = {502},
	pages = {527--539},
	pmid = {24058223},
	title = {{Effectively selecting a target population for a future comparative study}},
	volume = {108},
	year = {2013}
}

@article{Sham2014,
	author = {Sham, Pak C. and Purcell, Shaun M.},
	doi = {10.1038/nrg3706},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Sham, Purcell - 2014 - Statistical power and significance testing in large-scale genetic studies.pdf:pdf},
	issn = {1471-0056},
	journal = {Nature Reviews Genetics},
	number = {5},
	pages = {335--346},
	publisher = {Nature Publishing Group},
	title = {{Statistical power and significance testing in large-scale genetic studies}},
	url = {http://www.nature.com/doifinder/10.1038/nrg3706},
	volume = {15},
	year = {2014}
}

@article{Picard1984,
	abstract = {A methodolgy for assessment of the predictive ability of regression models is presented. Attention is given to models obtained via subset selection procedures, which are extremely difficult to evaluate by standard techniques. Cross-validatory assessments of predictive ability are obtained and their use illustrated in examples. ABSTRACT FROM AUTHOR},
	author = {Picard, Richard R. and Cook, R. Dennis},
	doi = {10.1080/01621459.1984.10478083},
	file = {:Users/boyiguo/Downloads/2288403.pdf:pdf},
	isbn = {01621459},
	issn = {1537274X},
	journal = {Journal of the American Statistical Association},
	keywords = {Data splitting,Model selection,Optimism principle,Prediction},
	number = {387},
	pages = {575--583},
	title = {{Cross-validation of regression models}},
	volume = {79},
	year = {1984}
}

@article{Spencer2009,
	author = {Spencer, Chris C. a. and Su, Zhan and Donnelly, Peter and Marchini, Jonathan},
	doi = {10.1371/journal.pgen.1000477},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Spencer et al. - 2009 - Designing Genome-Wide Association Studies Sample Size, Power, Imputation, and the Choice of Genotyping Chip.pdf:pdf},
	issn = {1553-7404},
	journal = {PLoS Genetics},
	number = {5},
	pages = {e1000477},
	title = {{Designing Genome-Wide Association Studies: Sample Size, Power, Imputation, and the Choice of Genotyping Chip}},
	url = {http://dx.plos.org/10.1371/journal.pgen.1000477},
	volume = {5},
	year = {2009}
}

@article{Zhang2015a,
	abstract = {A treatment regime formalizes personalized medicine as a function from individual patient characteristics to a recommended treatment. A high-quality treatment regime can improve patient outcomes while reducing cost, resource consumption, and treatment burden. Thus, there is tremendous interest in estimating treatment regimes from observational and randomized studies. However, the development of treatment regimes for application in clinical practice requires the long-term, joint effort of statisticians and clinical scientists. In this collaborative process, the statistician must integrate clinical science into the statistical models underlying a treatment regime and the clinician must scrutinize the estimated treatment regime for scientific validity. To facilitate meaningful information exchange, it is important that estimated treatment regimes be interpretable in a subject-matter context. We propose a simple, yet flexible class of treatment regimes whose members are representable as a short list of if-then statements. Regimes in this class are immediately interpretable and are therefore an appealing choice for broad application in practice. We derive a robust estimator of the optimal regime within this class and demonstrate its finite sample performance using simulation experiments. The proposed method is illustrated with data from two clinical trials.},
	archivePrefix = {arXiv},
	arxivId = {1504.07715},
	author = {Zhang, Yichi and Laber, Eric B. and Tsiatis, Anastasios and Davidian, Marie},
	doi = {10.1111/biom.12354},
	eprint = {1504.07715},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Zhang et al. - 2015 - Using decision lists to construct interpretable and parsimonious treatment regimes.pdf:pdf},
	issn = {15410420},
	journal = {Biometrics},
	keywords = {Decision lists,Exploratory analyses,Interpretability,Personalized medicine,Treatment regimes},
	number = {4},
	pages = {895--904},
	pmid = {26193819},
	title = {{Using decision lists to construct interpretable and parsimonious treatment regimes}},
	volume = {71},
	year = {2015}
}

@article{Regimes2016,
	author = {Regimes, Parsimonious Treatment},
	doi = {10.1111/biom.12354.Using},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Zhang et al. - 2015 - Using decision lists to construct interpretable and parsimonious treatment regimes.pdf:pdf},
	keywords = {decision lists,exploratory analyses,interpretability,personalized medicine,treatment regimes},
	number = {4},
	pages = {895--904},
	title = {{HHS Public Access}},
	volume = {71},
	year = {2016}
}

@article{Efron1997,
	abstract = {A study investigates the error rate of a rule for predicting future responses constructed from a training set of data. Results are nonparametric and apply to any possible prediction rule.},
	archivePrefix = {arXiv},
	arxivId = {arXiv:1011.1669v3},
	author = {Efron, Bradley and Tibshirani, Robert},
	doi = {10.1080/01621459.1997.10474007},
	eprint = {arXiv:1011.1669v3},
	isbn = {0162-1459},
	issn = {0162-1459},
	journal = {Journal of the American Statistical Association},
	keywords = {classification,cross-validation bootstrap,prediction rule},
	number = {438},
	pages = {548--560},
	pmid = {370},
	title = {{Improvements on Cross-Validation: The 632+ Bootstrap Method}},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1997.10474007},
	volume = {92},
	year = {1997}
}

@article{Feng2011,
	author = {Feng, Sheng and Wang, Shengchu and Chen, Chia-Cheng and Lan, Lan},
	doi = {10.1186/1471-2156-12-12},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Feng et al. - 2011 - GWAPower a statistical power calculation software for genome-wide association studies with quantitative traits.pdf:pdf},
	issn = {1471-2156},
	journal = {BMC Genetics},
	number = {1},
	pages = {12},
	publisher = {BioMed Central Ltd},
	title = {{GWAPower: a statistical power calculation software for genome-wide association studies with quantitative traits}},
	url = {http://www.biomedcentral.com/1471-2156/12/12},
	volume = {12},
	year = {2011}
}

@article{Pawitan2009,
	abstract = {A great majority of genetic markers discovered in recent genome-wide association studies have small effect sizes, and they explain only a small fraction of the genetic contribution to the diseases. How many more variants can we expect to discover and what study sizes are needed? We derive the connection between the cumulative risk of the SNP variants to the latent genetic risk model and heritability of the disease. We determine the sample size required for case-control studies in order to achieve a certain expected number of discoveries in a collection of most significant SNPs. Assuming similar allele frequencies and effect sizes of the currently validated SNPs, complex phenotypes such as type-2 diabetes would need approximately 800 variants to explain its 40{\%} heritability. Much smaller numbers of variants are needed if we assume rare-variants but higher penetrance models. We estimate that up to 50,000 cases and an equal number of controls are needed to discover 800 common low-penetrant variants among the top 5000 SNPs. Under common and rare low-penetrance models, the very large studies required to discover the numerous variants are probably at the limit of practical feasibility. Under rare-variant with medium- to high-penetrance models (odds-ratios between 1.6 and 4.0), studies comparable in size to many existing studies are adequate provided the genotyping technology can interrogate more and rarer variants},
	author = {Pawitan, Yudi and Seng, Ku Chee and Magnusson, Patrik K E},
	doi = {10.1371/journal.pone.0007969},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Pawitan, Seng, Magnusson - 2009 - How many genetic variants remain to be discovered.pdf:pdf},
	isbn = {1932-6203 (Electronic)$\backslash$r1932-6203 (Linking)},
	issn = {19326203},
	journal = {PLoS ONE},
	number = {12},
	pmid = {19956539},
	title = {{How many genetic variants remain to be discovered?}},
	volume = {4},
	year = {2009}
}

@article{Zhao2012,
	abstract = {There is increasing interest in discovering individualized treatment rules for patients who have heterogeneous responses to treatment. In particular, one aims to find an optimal individualized treatment rule which is a deterministic function of patient specific characteristics maximizing expected clinical outcome. In this paper, we first show that estimating such an optimal treatment rule is equivalent to a classification problem where each subject is weighted proportional to his or her clinical outcome. We then propose an outcome weighted learning approach based on the support vector machine framework. We show that the resulting estimator of the treatment rule is consistent. We further obtain a finite sample bound for the difference between the expected outcome using the estimated individualized treatment rule and that of the optimal treatment rule. The performance of the proposed approach is demonstrated via simulation studies and an analysis of chronic depression data.},
	archivePrefix = {arXiv},
	arxivId = {1508.03179},
	author = {Zhao, Yingqi and Zeng, Donglin and Rush, A. John and Kosorok, Michael R.},
	doi = {10.1080/01621459.2012.695674},
	eprint = {1508.03179},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Zhao et al. - 2012 - Estimating individualized treatment rules using outcome weighted learning.pdf:pdf},
	isbn = {0162-1459},
	issn = {01621459},
	journal = {Journal of the American Statistical Association},
	keywords = {Bayes classifier,Cross-validation,Dynamic treatment regime,Individualized treatment rule,RKHS,Risk bound,Weighted support vector machine},
	number = {499},
	pages = {1106--1118},
	pmid = {23630406},
	title = {{Estimating individualized treatment rules using outcome weighted learning}},
	volume = {107},
	year = {2012}
}

@article{Zhang2013,
	abstract = {A dynamic treatment regime is a list of sequential decision rules for assigning treatment based on a patient's history. Q- and A-learning are two main approaches for estimating the optimal regime, i.e., that yielding the most beneficial outcome in the patient population, using data from a clinical trial or observational study. Q-learning requires postulated regression models for the outcome, while A-learning involves models for that part of the outcome regression representing treatment contrasts and for treatment assignment. We propose an alternative to Q- and A-learning that maximizes a doubly robust augmented inverse probability weighted estimator for population mean outcome over a restricted class of regimes. Simulations demonstrate the method's performance and robustness to model misspecification, which is a key concern.},
	author = {Zhang, Baqun and Tsiatis, Anastasios A. and Laber, Eric B. and Davidian, Marie},
	doi = {10.1093/biomet/ast014},
	isbn = {0006-3444 (Print)$\backslash$r0006-3444 (Linking)},
	issn = {00063444},
	journal = {Biometrika},
	keywords = {A-learning,Double robustness,Outcome regression,Propensity score,Q-learning},
	number = {3},
	pages = {681--694},
	pmid = {24302771},
	title = {{Robust estimation of optimal dynamic treatment regimes for sequential treatment decisions}},
	volume = {100},
	year = {2013}
}

@article{Evans2012,
	author = {Evans, D. M. and Purcell, S.},
	doi = {10.1101/pdb.top069559},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Evans, Purcell - 2012 - Power Calculations in Genetic Studies.pdf:pdf},
	issn = {1559-6095},
	journal = {Cold Spring Harbor Protocols},
	number = {6},
	pages = {pdb.top069559--pdb.top069559},
	title = {{Power Calculations in Genetic Studies}},
	url = {http://www.cshprotocols.org/cgi/doi/10.1101/pdb.top069559},
	volume = {2012},
	year = {2012}
}

@article{Hardoon2004,
	abstract = {We present a general method using kernel canonical correlation analysis to learn a semantic representation to web images and their associated text. The semantic space provides a common representation and enables a comparison between the text and images. In the experiments, we look at two approaches of retrieving images based on only their content from a text query. We compare orthogonalization approaches against a standard cross-representation retrieval technique known as the generalized vector space model.},
	author = {Hardoon, DR David R and Szedmak, Sandor and Shawe-Taylor, John},
	doi = {10.1162/0899766042321814},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Hardoon, Szedmak, Shawe-Taylor - 2004 - Canonical correlation analysis An overview with application to learning methods.pdf:pdf},
	isbn = {0899-7667},
	issn = {0899-7667},
	journal = {Neural Computation},
	keywords = {CCA,Machine Learning},
	mendeley-tags = {CCA,Machine Learning},
	number = {12},
	pages = {2639--64},
	pmid = {15516276},
	title = {{Canonical correlation analysis: An overview with application to learning methods}},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/15516276{\%}5Cnhttp://www.mitpressjournals.org/doi/abs/10.1162/0899766042321814},
	volume = {16},
	year = {2004}
}

@article{Su2009,
  title={Subgroup analysis via recursive partitioning},
  author={Su, Xiaogang and Tsai, Chih-Ling and Wang, Hansheng and Nickerson, David M and Li, Bogong},
  journal={Journal of Machine Learning Research},
  volume={10},
  number={Feb},
  pages={141--158},
  year={2009}
}


@article{Mirnezami2012,
	abstract = {Ms. H. is a 35-year-old woman from Japan who has had a cough for 3 weeks. Her physician sends her for an x-ray and CT scan that reveal an advanced lesion, which a biopsy confirms to be non-small-cell lung cancer. She has never smoked. Can anything be done for her? Had Ms. H.'s cancer been diagnosed before 2004, her oncologist might have offered her a treatment to which about 10{\%} of patients have a response, with the remainder gaining a negligible survival benefit and experiencing clinically significant side effects. But her diagnosis was made in 2011, when her biopsy tissue . . .},
	author = {Mirnezami, Reza and Nicholson, Jeremy and Darzi, Ara},
	doi = {10.1056/NEJMp1114866},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Mirnezami, Nicholson, Darzi - 2012 - Preparing for Precision Medicine.pdf:pdf},
	isbn = {1533-4406 (Electronic)$\backslash$r0028-4793 (Linking)},
	issn = {0028-4793},
	journal = {New England Journal of Medicine},
	number = {6},
	pages = {489--491},
	pmid = {22256780},
	title = {{Preparing for Precision Medicine}},
	url = {http://www.nejm.org/doi/abs/10.1056/NEJMp1114866},
	volume = {366},
	year = {2012}
}



@article{Zhang2012,
	abstract = {A treatment regime maps observed patient characteristics to a recommended treatment. Recent technological advances have increased the quality, accessibility, and volume of patient-level data; consequently, there is a growing need for powerful and flexible estimators of an optimal treatment regime that can be used with either observational or randomized clinical trial data. We propose a novel and general framework that transforms the problem of estimating an optimal treatment regime into a classification problem wherein the optimal classifier corresponds to the optimal treatment regime. We show that commonly employed parametric and semi-parametric regression estimators, as well as recently proposed robust estimators of an optimal treatment regime can be represented as special cases within our framework. Furthermore, our approach allows any classification procedure that can accommodate case weights to be used without modification to estimate an optimal treatment regime. This introduces a wealth of new and powerful learning algorithms for use in estimating treatment regimes. We illustrate our approach using data from a breast cancer clinical trial.},
	author = {Zhang, Baqun and Tsiatis, Anastasios A. and Davidian, Marie and Zhang, Min and Laber, Eric},
	doi = {10.1002/sta.411},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Zhang et al. - 2012 - Estimating optimal treatment regimes from a classification perspective.pdf:pdf},
	issn = {20491573},
	journal = {Stat},
	keywords = {Classification,Doubly robust estimator,Inverse probability weighting,Personalized medicine,Potential outcomes,Propensity score},
	number = {1},
	pages = {103--114},
	pmid = {23645940},
	title = {{Estimating optimal treatment regimes from a classification perspective}},
	volume = {1},
	year = {2012}
}

@article{Browne2000,
	abstract = {This paper gives a review of cross-validation methods. The original applications in multiple linear regression are considered first. It is shown how predictive accuracy depends on sample size and the number of predictor variables. Both two-sample and single-sample cross-validation indices are investigated. The application of cross-validation methods to the analysis of moment structures is then justified. An equivalence of a single-sample cross-validation index and the Akaike information criterion is pointed out. It is seen that the optimal number of parameters suggested by both single-sample and two-sample cross-validation indices will depend on sample size. Copyright 2000 Academic Press.},
	author = {Browne, Michael W},
	doi = {10.1006/jmps.1999.1279},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Browne - 2000 - Cross-Validation Methods.pdf:pdf},
	isbn = {0022-2496},
	issn = {00222496},
	journal = {Journal of Mathematical Psychology},
	number = {1},
	pages = {108--132},
	pmid = {10733860},
	title = {{Cross-Validation Methods}},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0022249699912798},
	volume = {44},
	year = {2000}
}

@article{Lipkovich2011,
	abstract = {We propose a novel recursive partitioning method for identifying subgroups of subjects with enhanced treatment effects based on a differential effect search algorithm. The idea is to build a collection of subgroups by recursively partitioning a database into two subgroups at each parent group, such that the treatment effect within one of the two subgroups is maximized compared with the other subgroup. The process of data splitting continues until a predefined stopping condition has been satisfied. The method is similar to 'interaction tree' approaches that allow incorporation of a treatment-by-split interaction in the splitting criterion. However, unlike other tree-based methods, this method searches only within specific regions of the covariate space and generates multiple subgroups of potential interest. We develop this method and provide guidance on key topics of interest that include generating multiple promising subgroups using different splitting criteria, choosing optimal values of complexity parameters via cross-validation, and addressing Type I error rate inflation inherent in data mining applications using a resampling-based method. We evaluate the operating characteristics of the procedure using a simulation study and illustrate the method with a clinical trial example. Copyright {\textcopyright} 2011 John Wiley {\&} Sons, Ltd.},
	author = {Lipkovich, Ilya and Dmitrienko, Alex and Denne, Jonathan and Enas, Gregory},
	doi = {10.1002/sim.4289},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Lipkovich et al. - 2011 - Subgroup identification based on differential effect search-A recursive partitioning method for establishing r.pdf:pdf},
	isbn = {1097-0258 (Electronic)$\backslash$r0277-6715 (Linking)},
	issn = {02776715},
	journal = {Statistics in Medicine},
	keywords = {Data mining,Recursive partitioning,Subgroup analysis in clinical trials},
	number = {21},
	pages = {2601--2621},
	pmid = {21786278},
	title = {{Subgroup identification based on differential effect search-A recursive partitioning method for establishing response to treatment in patient subpopulations}},
	volume = {30},
	year = {2011}
}

@article{Foster2011a,
	abstract = {We consider the problem of identifying a subgroup of patients who may have an enhanced treatment effect in a randomized clinical trial, and it is desirable that the subgroup be defined by a limited number of covariates. For this problem, the development of a standard, pre-determined strategy may help to avoid the well-known dangers of subgroup analysis. We present a method developed to find subgroups of enhanced treatment effect. This method, referred to as 'Virtual Twins', involves predicting response probabilities for treatment and control 'twins' for each subject. The difference in these probabilities is then used as the outcome in a classification or regression tree, which can potentially include any set of the covariates. We define a measure Q({\^{A}}) to be the difference between the treatment effect in estimated subgroup {\^{A}} and the marginal treatment effect. We present several methods developed to obtain an estimate of Q({\^{A}}), including estimation of Q({\^{A}}) using estimated probabilities in the original data, using estimated probabilities in newly simulated data, two cross-validation-based approaches, and a bootstrap-based bias-corrected approach. Results of a simulation study indicate that the Virtual Twins method noticeably outperforms logistic regression with forward selection when a true subgroup of enhanced treatment effect exists. Generally, large sample sizes or strong enhanced treatment effects are needed for subgroup estimation. As an illustration, we apply the proposed methods to data from a randomized clinical trial.},
	archivePrefix = {arXiv},
	arxivId = {NIHMS150003},
	author = {Foster, Jared C. and Taylor, Jeremy M G and Ruberg, Stephen J.},
	doi = {10.1002/sim.4322},
	eprint = {NIHMS150003},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Foster, Taylor, Ruberg - 2011 - Subgroup identification from randomized clinical trial data.pdf:pdf},
	isbn = {1097-0258 (Electronic)$\backslash$r0277-6715 (Linking)},
	issn = {02776715},
	journal = {Statistics in Medicine},
	keywords = {Random forests,Randomized clinical trials,Regression trees,Subgroups,Tailored therapeutics},
	number = {24},
	pages = {2867--2880},
	pmid = {21815180},
	title = {{Subgroup identification from randomized clinical trial data}},
	volume = {30},
	year = {2011}
}

@article{Purcell2003,
	abstract = {SUMMARY: A website for performing power calculations for the design of linkage and association genetic mapping studies of complex traits. AVAILABILITY: The package is made available athttp://statgen.iop.kcl.ac.uk/gpc/.},
	author = {Purcell, S and Cherny, S S and Sham, P C},
	doi = {10.1093/bioinformatics/19.1.149},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Purcell, Cherny, Sham - 2003 - Genetic Power Calculator design of linkage and association genetic mapping studies of complex traits.pdf:pdf},
	isbn = {1367-4803},
	issn = {1367-4803},
	journal = {Bioinformatics (Oxford, England)},
	number = {1},
	pages = {149--150},
	pmid = {12499305},
	title = {{Genetic Power Calculator: design of linkage and association genetic mapping studies of complex traits.}},
	volume = {19},
	year = {2003}
}

@article{Kelley2012,
	abstract = {The call for researchers to report and interpret effect sizes and their corresponding confidence intervals has never been stronger. However, there is confusion in the literature on the definition of effect size, and consequently the term is used inconsistently. We propose a definition for effect size, discuss 3 facets of effect size (dimension, measure/index, and value), outline 10 corollaries that follow from our definition, and review ideal qualities of effect sizes. Our definition of effect size is general and subsumes many existing definitions of effect size. We define effect size as a quantitative reflection of the magnitude of some phenomenon that is used for the purpose of addressing a question of interest. Our definition of effect size is purposely more inclusive than the way many have defined and conceptualized effect size, and it is unique with regard to linking effect size to a question of interest. Additionally, we review some important developments in the effect size literature and discuss the importance of accompanying an effect size with an interval estimate that acknowledges the uncertainty with which the population value of the effect size has been estimated. We hope that this article will facilitate discussion and improve the practice of reporting and interpreting effect sizes. (PsycINFO Database Record (c) 2012 APA, all rights reserved). (journal abstract)},
	author = {Kelley, K. and Preacher, K. J.},
	doi = {10.1037/a0028086},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Kelley, Preacher - 2012 - On effect size.pdf:pdf},
	isbn = {1082-989X$\backslash$r1939-1463},
	issn = {1939-1463},
	journal = {Psychological Methods},
	keywords = {a,and professional organizations to,by methodologists,confidence intervals,corresponding confidence intervals as,effect size,effect sizes and their,jour-,nal editors,report,reporting results,research design,research question,researchers are commonly advised,reviewers},
	number = {2},
	pages = {137--152},
	pmid = {22545595},
	title = {{On effect size}},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0028086},
	volume = {17},
	year = {2012}
}

@article{Zhang2015b,
	abstract = {While there are various model selection methods, an unanswered but important question is how to select one of them for data at hand. The difficulty is due to that the targeted behaviors of the model selection procedures depend heavily on uncheckable or difficult-to-check assumptions on the data generating process. Fortunately, cross-validation (CV) provides a general tool to solve this problem. In this work, results are provided on how to apply CV to consistently choose the best method, yielding new insights and guidance for potentially vast amount of application. In addition, we address several seemingly widely spread misconceptions on CV.},
	author = {Zhang, Yongli and Yang, Yuhong},
	doi = {10.1016/j.jeconom.2015.02.006},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Zhang, Yang - 2015 - Cross-validation for selecting a model selection procedure.pdf:pdf},
	isbn = {0304-4076},
	issn = {18726895},
	journal = {Journal of Econometrics},
	keywords = {Adaptive procedure selection,Cross-validation,Cross-validation paradox,Data splitting ratio,Information criterion,LASSO,MCP,SCAD},
	number = {1},
	pages = {95--112},
	publisher = {Elsevier B.V.},
	title = {{Cross-validation for selecting a model selection procedure}},
	url = {http://dx.doi.org/10.1016/j.jeconom.2015.02.006},
	volume = {187},
	year = {2015}
}

@article{Hastie2009,
	abstract = {During the past decade there has been an explosion in computation and information technology. With it has come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It should be a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting-the first comprehensive treatment of this topic in any book. Trevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. They are prominent researchers in this area: Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie wrote much of the statistical modeling software in S-PLUS and invented principal curves and surfaces. Tibshirani proposed the Lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, and projection pursuit. FROM THE REVIEWS: TECHNOMETRICS "This is a vast and complex book. Generally, it concentrates on explaining why and how the methods work, rather than how to use them. Examples and especially the visualizations are principle features...As a source for the methods of statistical learning...it will probably be a long time before there is a competitor to this book."},
	archivePrefix = {arXiv},
	arxivId = {1010.3003},
	author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
	doi = {10.1007/b94608},
	eprint = {1010.3003},
	isbn = {9780387848570},
	issn = {03436993},
	journal = {Elements},
	pages = {337--387},
	pmid = {15512507},
	title = {{The Elements of Statistical Learning}},
	url = {http://www.springerlink.com/index/10.1007/b94608},
	volume = {1},
	year = {2009}
}

@article{Wong2015,
	abstract = {Classification is an essential task for predicting the class values of new instances. Both k-fold and leave-one-out cross validation are very popular for evaluating the performance of classification algorithms. Many data mining literatures introduce the operations for these two kinds of cross validation and the statistical methods that can be used to analyze the resulting accuracies of algorithms, while those contents are generally not all consistent. Analysts can therefore be confused in performing a cross validation procedure. In this paper, the independence assumptions in cross validation are introduced, and the circumstances that satisfy the assumptions are also addressed. The independence assumptions are then used to derive the sampling distributions of the point estimators for k-fold and leave-one-out cross validation. The cross validation procedure to have such sampling distributions is discussed to provide new insights in evaluating the performance of classification algorithms.},
	author = {Wong, Tzu Tsung},
	doi = {10.1016/j.patcog.2015.03.009},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Wong - 2015 - Performance evaluation of classification algorithms by k-fold and leave-one-out cross validation.pdf:pdf},
	issn = {00313203},
	journal = {Pattern Recognition},
	keywords = {Classification,Independence,Leave-one-out cross validation,Sampling distribution,k-Fold cross validation},
	number = {9},
	pages = {2839--2846},
	publisher = {Elsevier},
	title = {{Performance evaluation of classification algorithms by k-fold and leave-one-out cross validation}},
	url = {http://dx.doi.org/10.1016/j.patcog.2015.03.009},
	volume = {48},
	year = {2015}
}

@article{Drevets2009,
	abstract = {The anterior cingulate cortex (ACC) ventral to the genu of the corpus callosum has been implicated in the modulation of emotional behavior on the basis of neuroimaging studies in humans and lesion analyses in experimental animals. In a combined positron emission tomography/magnetic resonance imaging study of mood disorders, we demonstrated that the mean gray matter volume of this "subgenual" ACC (sgACC) cortex is abnormally reduced in subjects with major depressive disorder (MDD) and bipolar disorder, irrespective of mood state. Neuropathological assessments of sgACC tissue acquired postmortem from subjects with MDD or bipolar disorder confirmed the decrement in gray matter volume, and revealed that this abnormality was associated with a reduction in glia, with no equivalent loss of neurons. In positron emission tomography studies, the metabolic activity was elevated in this region in the depressed relative to the remitted phases of the same MDD subjects, and effective antidepressant treatment was associated with a reduction in sgACC activity. Other laboratories replicated and extended these findings, and the clinical importance of this treatment effect was underscored by a study showing that deep brain stimulation of the sgACC ameliorates depressive symptoms in treatment-resistant MDD. This article discusses the functional significance of these findings within the context of the preclinical literature that implicates the putative homologue of this region in the regulation of emotional behavior and stress response. In experimental animals, this region participates in an extended "visceromotor network" of structures that modulates autonomic/neuroendocrine responses and neurotransmitter transmission during the neural processing of reward, fear, and stress. These data thus hold important implications for the development of neural models of depression that can account for the abnormal motivational, neuroendocrine, autonomic, and emotional manifestations evident in human mood disorders.},
	annote = {missing heritability},
	archivePrefix = {arXiv},
	arxivId = {NIHMS150003},
	author = {Drevets, Wayne C and Savitz, Jonathan and Trimble, Michael},
	doi = {10.1038/nature08494.},
	eprint = {NIHMS150003},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Drevets, Savitz, Trimble - 2009 - Finding the missing heritability of complex diseases.pdf:pdf},
	isbn = {1092-8529 (Print)},
	issn = {1092-8529},
	journal = {Nature},
	number = {8},
	pages = {663--81},
	pmid = {18704022},
	title = {{Finding the missing heritability of complex diseases}},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/18704022{\%}5Cnhttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2729429},
	volume = {13},
	year = {2009}
}

@book{Ellis2010,
	abstract = {This succinct and jargon-free introduction to effect sizes gives students and researchers the tools they need to interpret the practical significance of their results. Using a class-tested approach that includes numerous examples and step-by-step exercises, it introduces and explains three of the most important issues relating to the practical significance of research results: the reporting and interpretation of effect sizes (Part I), the analysis of statistical power (Part II), and the meta-analytic pooling of effect size estimates drawn from different studies (Part III). The book concludes with a handy list of recommendations for those actively engaged in or currently preparing research projects.},
	author = {Ellis, Paul D.},
	doi = {10.1017/cbo9780511761676},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Ellis - 2010 - The Essential Guide to Effect Sizes Statistical Power, Meta-Analysis, and the Interpretation of Research Results.pdf:pdf},
	isbn = {0521142466},
	pages = {194},
	title = {{The Essential Guide to Effect Sizes: Statistical Power, Meta-Analysis, and the Interpretation of Research Results}},
	url = {http://www.amazon.com/Essential-Guide-Effect-Sizes-Interpretation/dp/0521142466},
	year = {2010}
}

@article{Pearson2008,
	author = {Pearson, Thomas a.},
	doi = {10.1001/jama.299.11.1335},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Pearson - 2008 - How to Interpret a Genome-wide Association Study.pdf:pdf},
	issn = {0098-7484},
	journal = {Jama},
	number = {11},
	pages = {1335},
	title = {{How to Interpret a Genome-wide Association Study}},
	url = {http://jama.jamanetwork.com/article.aspx?doi=10.1001/jama.299.11.1335},
	volume = {299},
	year = {2008}
}

@article{Witte2014,
	author = {Witte, John S},
	doi = {10.1146/annurev.publhealth.012809.103723.Genome-Wide},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Witte - 2014 - Genome-wide association studies and beyond.pdf:pdf},
	keywords = {copy number,linkage disequilibrium,population stratification,single nucleotide polymorphism},
	number = {77},
	pages = {9--20},
	title = {{Genome-wide association studies and beyond}},
	year = {2014}
}

@article{Sullivan2012a,
	abstract = {Statistical significance is the least interesting thing about the results. You should describe the results in terms of measures of magnitude –not just, does a treatment affect people, but how much does it affect them. The primary product of a research inquiry is one or more measures of effect size, not P values.},
	archivePrefix = {arXiv},
	arxivId = {arXiv:1011.1669v3},
	author = {Sullivan, Gail M. and Feinn, Richard},
	doi = {10.4300/JGME-D-12-00156.1},
	eprint = {arXiv:1011.1669v3},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Sullivan, Feinn - 2012 - Using Effect Size—or Why the iPi Value Is Not Enough.pdf:pdf},
	isbn = {1949-8349 1949-8357},
	issn = {1949-8349},
	journal = {Journal of Graduate Medical Education},
	number = {3},
	pages = {279--282},
	pmid = {23997866},
	title = {{Using Effect Size—or Why the {\textless}i{\textgreater}P{\textless}/i{\textgreater} Value Is Not Enough}},
	url = {http://www.jgme.org/doi/abs/10.4300/JGME-D-12-00156.1},
	volume = {4},
	year = {2012}
}

@article{Sega2011,
	abstract = {Random forests have emerged as a versatile and highly accurate classification and regression methodology, requiring little tuning and providing interpretable outputs. Here, we briefly outline the genesis of, and motivation for, the random forest paradigm as an outgrowth from earlier tree-structured techniques. We elaborate on aspects of prediction error and attendant tuning parameter issues. However, our emphasis is on extending the random forest schema to the multiple response setting. We provide a simple illustrative example from ecology that showcases the improved fit and enhanced interpretation afforded by the random forest framework. {\textcopyright} 2011 John Wiley {\&} Sons, Inc. WIREs Data Mining Knowl Discov 2011 1 80-87 DOI: 10.1002/widm.12},
	author = {Sega, Mark and Xiao, Yuanyuan},
	doi = {10.1002/widm.12},
	isbn = {1942-4795},
	issn = {19424787},
	journal = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
	number = {1},
	pages = {80--87},
	title = {{Multivariate random forests}},
	volume = {1},
	year = {2011}
}

@article{Moore2010,
	abstract = {MOTIVATION: The sequencing of the human genome has made it possible to identify an informative set of {\textgreater}1 million single nucleotide polymorphisms (SNPs) across the genome that can be used to carry out genome-wide association studies (GWASs). The availability of massive amounts of GWAS data has necessitated the development of new biostatistical methods for quality control, imputation and analysis issues including multiple testing. This work has been successful and has enabled the discovery of new associations that have been replicated in multiple studies. However, it is now recognized that most SNPs discovered via GWAS have small effects on disease susceptibility and thus may not be suitable for improving health care through genetic testing. One likely explanation for the mixed results of GWAS is that the current biostatistical analysis paradigm is by design agnostic or unbiased in that it ignores all prior knowledge about disease pathobiology. Further, the linear modeling framework that is employed in GWAS often considers only one SNP at a time thus ignoring their genomic and environmental context. There is now a shift away from the biostatistical approach toward a more holistic approach that recognizes the complexity of the genotype-phenotype relationship that is characterized by significant heterogeneity and gene-gene and gene-environment interaction. We argue here that bioinformatics has an important role to play in addressing the complexity of the underlying genetic basis of common human diseases. The goal of this review is to identify and discuss those GWAS challenges that will require computational methods.},
	annote = {GWAS analysis from a data mining and machine learning perspective
	Read later},
	author = {Moore, Jason H. and Asselbergs, Folkert W. and Williams, Scott M.},
	doi = {10.1093/bioinformatics/btp713},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Moore, Asselbergs, Williams - 2010 - Bioinformatics challenges for genome-wide association studies.pdf:pdf},
	isbn = {1367-4811 (Electronic)$\backslash$r1367-4803 (Linking)},
	issn = {13674803},
	journal = {Bioinformatics},
	number = {4},
	pages = {445--455},
	pmid = {20053841},
	title = {{Bioinformatics challenges for genome-wide association studies}},
	volume = {26},
	year = {2010}
}

@article{Laber2015a,
	abstract = {Individualized treatment rules recommend treatments on the basis of individual patient characteristics. A high-quality treatment rule can produce better patient outcomes, lower costs and less treatment burden. If a treatment rule learned from data is to be used to inform clinical practice or provide scientific insight, it is crucial that it be interpretable; clinicians may be unwilling to implement models they do not understand, and black-box models may not be useful for guiding future research. The canonical example of an interpretable predictionmodel is a decision tree. We propose a method for estimating an optimal individualized treatment rule within the class of rules that are representable as decision trees. The class of rules we consider is interpretable but expressive. Anovel feature of this problemis that the learning task is unsupervised, as the optimal treatment for each patient is unknown and must be estimated. The proposed method applies to both categorical and continuous treatments and produces favourable marginal mean outcomes in simulation experiments. We illustrate it using data from a study of major depressive disorder.},
	archivePrefix = {arXiv},
	arxivId = {15334406},
	author = {Laber, E. B. and Zhao, Y. Q.},
	doi = {10.1093/biomet/asv028},
	eprint = {15334406},
	file = {:Users/boyiguo/Library/Application Support/Mendeley Desktop/Downloaded/Laber, Zhao - 2015 - Tree-based methods for individualized treatment regimes.pdf:pdf},
	isbn = {0000000000000},
	issn = {14643510},
	journal = {Biometrika},
	keywords = {Continuous treatment,Exploratory analysis,Personalized medicine,Treatment regime,Tree-based method},
	number = {3},
	pages = {501--514},
	pmid = {26893526},
	title = {{Tree-based methods for individualized treatment regimes}},
	volume = {102},
	year = {2015}
}

@article{wager2018estimation,
  title={Estimation and inference of heterogeneous treatment effects using random forests},
  author={Wager, Stefan and Athey, Susan},
  journal={Journal of the American Statistical Association},
  volume={113},
  number={523},
  pages={1228--1242},
  year={2018},
  publisher={Taylor \& Francis}
}

@article{tian2014simple,
  title={A simple method for estimating interactions between a treatment and a large number of covariates},
  author={Tian, Lu and Alizadeh, Ash A and Gentles, Andrew J and Tibshirani, Robert},
  journal={Journal of the American Statistical Association},
  volume={109},
  number={508},
  pages={1517--1532},
  year={2014},
  publisher={Taylor \& Francis}
}


 @Manual{Rcite,
    title = {R: A Language and Environment for Statistical Computing},
    author = {{R Core Team}},
    organization = {R Foundation for Statistical Computing},
    address = {Vienna, Austria},
    year = {2019},
    url = {https://www.R-project.org/},
  }
  
    @Article{liaw2002classification,
    title = {Classification and Regression by randomForest},
    author = {Andy Liaw and Matthew Wiener},
    journal = {R News},
    year = {2002},
    volume = {2},
    number = {3},
    pages = {18-22},
    url = {https://CRAN.R-project.org/doc/Rnews/},
  }
  
  @Article{glmnet,
    title = {Regularization Paths for Cox's Proportional Hazards Model via Coordinate Descent},
    author = {Noah Simon and Jerome Friedman and Trevor Hastie and Rob Tibshirani},
    journal = {Journal of Statistical Software},
    year = {2011},
    volume = {39},
    number = {5},
    pages = {1--13}
  }
  
  @Article{RRF,
    title = {Classification and Regression by randomForest},
    author = {Andy Liaw and Matthew Wiener},
    journal = {R News},
    year = {2002},
    volume = {2},
    number = {3},
    pages = {18-22},
    url = {https://CRAN.R-project.org/doc/Rnews/},
  }
  
  @article{peterson2016joint,
  title={Joint Bayesian variable and graph selection for regression models with network-structured predictors},
  author={Peterson, Christine B and Stingo, Francesco C and Vannucci, Marina},
  journal={Statistics in medicine},
  volume={35},
  number={7},
  pages={1017--1031},
  year={2016},
  publisher={Wiley Online Library}
}

@article{chen2013structure,
  title={Structure-constrained sparse canonical correlation analysis with an application to microbiome data analysis},
  author={Chen, Jun and Bushman, Frederic D and Lewis, James D and Wu, Gary D and Li, Hongzhe},
  journal={Biostatistics},
  volume={14},
  number={2},
  pages={244--258},
  year={2013},
  publisher={Oxford University Press}
}

@article{breiman2001statistical,
  title={Statistical modeling: The two cultures},
  author={Breiman, Leo},
  journal={Statistical science},
  volume={16},
  number={3},
  pages={199--231},
  year={2001},
  publisher={Institute of Mathematical Statistics}
}

@article{vartoukian2007division,
  title={The division “synergistes”},
  author={Vartoukian, Sonia R and Palmer, Richard M and Wade, William G},
  journal={Anaerobe},
  volume={13},
  number={3-4},
  pages={99--106},
  year={2007},
  publisher={Elsevier}
}

@article{callahan2016bioconductor,
  title={Bioconductor workflow for microbiome data analysis: from raw reads to community analyses},
  author={Callahan, Ben J and Sankaran, Kris and Fukuyama, Julia A and McMurdie, Paul J and Holmes, Susan P},
  journal={F1000Research},
  volume={5},
  year={2016},
  publisher={Faculty of 1000 Ltd}
}

@article{ryan2014fxr,
  title={FXR is a molecular target for the effects of vertical sleeve gastrectomy},
  author={Ryan, Karen K and Tremaroli, Valentina and Clemmensen, Christoffer and Kovatcheva-Datchary, Petia and Myronovych, Andriy and Karns, Rebekah and Wilson-P{\'e}rez, Hilary E and Sandoval, Darleen A and Kohli, Rohit and B{\"a}ckhed, Fredrik and others},
  journal={Nature},
  volume={509},
  number={7499},
  pages={183--188},
  year={2014},
  publisher={Nature Publishing Group}
}

@article{davies2014random,
  title={The random forest kernel and creating other kernels for big data from random partitions},
  author={Davies, Alex and Ghahramani, Zoubin},
  journal={arXiv preprint arXiv:1402.4293},
  year={2014}
}


@article{Avocado,
  title={Avocado consumption alters gastrointestinal bacteria abundance and microbial metabolite concentrations among adults with overweight or obesity: a randomized, controlled trial},
  author={Thompson, SV and Bailey, MA and Taylor, AM and Kaczmarek, JL and Krug, AR and Edwards, CG and Reeser, GE and Burd, NA and Khan, NA and Holscher, HD},
  journal={The Journal of Nutrition  (accepted)},
  year={2020}
}

@article{tenenhaus2014variable,
  title={Variable selection for generalized canonical correlation analysis},
  author={Tenenhaus, Arthur and Philippe, Cathy and Guillemot, Vincent and Le Cao, Kim-Anh and Grill, Jacques and Frouin, Vincent},
  journal={Biostatistics},
  volume={15},
  number={3},
  pages={569--583},
  year={2014},
  publisher={Oxford University Press}
}

@article{gebauer2016food,
  title={Food processing and structure impact the metabolizable energy of almonds},
  author={Gebauer, Sarah K and Novotny, Janet A and Bornhorst, Gail M and Baer, David J},
  journal={Food \& function},
  volume={7},
  number={10},
  pages={4231--4238},
  year={2016},
  publisher={Royal Society of Chemistry}
}

@article{natividad2018bilophila,
  title={Bilophila wadsworthia aggravates high fat diet induced metabolic dysfunctions in mice},
  author={Natividad, Jane M and Lamas, Bruno and Pham, Hang Phuong and Michel, Marie-Laure and Rainteau, Dominique and Bridonneau, Chantal and da Costa, Gregory and van Hylckama Vlieg, Johan and Sovran, Bruno and Chamignon, Celia and others},
  journal={Nature communications},
  volume={9},
  number={1},
  pages={1--15},
  year={2018},
  publisher={Nature Publishing Group}
}

@article{biagi2016gut,
  title={Gut microbiota and extreme longevity},
  author={Biagi, Elena and Franceschi, Claudio and Rampelli, Simone and Severgnini, Marco and Ostan, Rita and Turroni, Silvia and Consolandi, Clarissa and Quercia, Sara and Scurti, Maria and Monti, Daniela and others},
  journal={Current Biology},
  volume={26},
  number={11},
  pages={1480--1485},
  year={2016},
  publisher={Elsevier}
}

@article{ozato2019blautia,
  title={Blautia genus associated with visceral fat accumulation in adults 20--76 years of age},
  author={Ozato, Naoki and Saito, Shinichiro and Yamaguchi, Tohru and Katashima, Mitsuhiro and Tokuda, Itoyo and Sawada, Kaori and Katsuragi, Yoshihisa and Kakuta, Masanori and Imoto, Seiya and Ihara, Kazushige and others},
  journal={npj Biofilms and Microbiomes},
  volume={5},
  number={1},
  pages={1--9},
  year={2019},
  publisher={Nature Publishing Group}
}